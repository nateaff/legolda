<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Nathanael Aff" />


<title>Training the model</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">legolda</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/nateaff/legolda">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Training the model</h1>
<h4 class="author"><em>Nathanael Aff</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Insert last udpate and git version-->
<p><strong>Last updated:</strong> 2017-09-13</p>
<p><strong>Code version:</strong> 880af53</p>
<div id="selecting-a-topic-model" class="section level1">
<h1>Selecting a topic model</h1>
<p>Up to this point, we’ve been using the full data set. (Actually, I’m not including some data so I should say, almost the full data set). Solving the LDA problem is computationally intensive, so for the remaining examples, we’re going to work with a very small sample of the data, just 250 sets of the 11,000 set total.</p>
<div id="cross-validation-on-perplexity" class="section level2">
<h2>Cross validation on perplexity</h2>
<p>The LDA model learns to posterior distributions which are the optimization routine’s best guess at the distributions that generated the data. One method to test how good those distributions fit our data is to compare the learned distribution on a training set to the distribution of a holdout set. Perplexity is one measure of the difference between estimated topic distributions on documents.</p>
<p>We cast the set_word table to a document term matrix using the <code>tidytext</code> function. This returns a<code>documentTermMatrix</code> object from the <code>tm</code> package. The LDA function we use is from the <code>topicmodels</code> package. It has a variational expectation maximation method and a Gibbs sampling method and I used the former.</p>
<pre><code>Connecting to database 
Assigning themes to theme_df 
Assigning sets to sets_df 
Retrieving dataset form db 
Disconnecting from database 
Assigning full set set inventories to &#39;set_colors&#39; 
Assigning values to total_words
Assigning tidy set and color dataframe to &#39;set_words&#39; 
Creating sparse document term matrix (tm-package) and assigning to &#39;dtm&#39; </code></pre>
<pre class="r"><code>perplexities &lt;- readRDS(here::here(&quot;inst&quot;, &quot;data&quot;, &quot;perplexity_all.RDS&quot;))</code></pre>
<div id="k-topic-grid" class="section level3">
<h3>K-topic grid</h3>
<p>Since I tested the running time on different set numbers I have seen that for this small number of sets there aren’t many topics. I’m putting a few more topic values <span class="math inline">\(k\)</span> on the lower end but including some higher values to better see the trend.</p>
<p>Perplexity decreases with more topics but the rate of decrease changes around 10 to 15.</p>
<pre class="r"><code>perplexities %&gt;% ggplot(aes(n_topic, perplexity)) + geom_point(aes(colour = fold), 
    size = 2) + geom_line(aes(n_topic, perplexity, group = fold, colour = fold)) + 
    scale_color_manual(values = pal21(), guide = guide_legend(title = &quot;Folds&quot;)) + 
    geom_smooth(se = FALSE, colour = &quot;#2f2f2a&quot;) + scale_x_continuous(breaks = perplexities$n_topic) + 
    labs(x = &quot;Number of topics&quot;, y = &quot;Perplexity&quot;, title = &quot;Perplexities scores for LDA models&quot;, 
        subtitle = &quot;Perplexity (lower is better) of holdout sets for 5-fold cross-validation&quot;) + 
    legolda::theme_scatter(bgcol = &quot;#f8f8f8&quot;)</code></pre>
<p><img src="figure/train-model.Rmd/cv-result-plot-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ntopics &lt;- c(20, 30, 35, 40, 50, 75, 100)
# Train LDA models on full data set
if (!from_cache) {
    lda_models &lt;- c(20, 30, 35, 40, 50, 75, 100) %&gt;% purrr::map(LDA, x = dtm, 
        control = list(seed = 1))
}</code></pre>
</div>
</div>
<div id="other-measures-of-topic-quality" class="section level2">
<h2>Other measures of topic quality</h2>
<p>The <code>ldatuning</code> package has several other metrics of the quality of the topic models. I have modified the main function from the package to only return the scores. (The original package computes the models first and then the scores).</p>
<pre class="r"><code>knitr::read_chunk(here::here(&quot;code&quot;, &quot;ldatuning-scores.R&quot;))</code></pre>
<pre class="r"><code>lda_models &lt;- readRDS(here::here(&quot;inst&quot;, &quot;data&quot;, &quot;lda_models_all.RDS&quot;))
lda_metrics &lt;- legolda::score_models(lda_models, dtm, topics = ntopics)

plot_lda_scores(lda_metrics, title)</code></pre>
<p><img src="figure/train-model.Rmd/ldatuning-scores-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div id="interpreting-the-topic-metrics" class="section level3">
<h3>Interpreting the topic metrics</h3>
<p>What are these measures? I skimmed two of the references in the <code>ldatuning</code> package but I don’t understand them enough to give a brief interpretation of what the scores mean.</p>
<p>There is no agreement here although two measures change most between 5 and 15, although it is in opposite directions. Along with the perplexity numbers, it might suggest a value around 12. Here I’m informally assuming that we’re not gaining much information for <span class="math inline">\(k\)</span> greater than 20.</p>
</div>
</div>
<div id="topic-coherence" class="section level2">
<h2>Topic coherence</h2>
<p>There are several version of topic coherence which measure the pairwise strength of the relationship of the top terms in a topic model. Given some score where a larger value indicates a stronger relation ship between two words <span class="math inline">\(w_i, w_j\)</span>, a generic coherence score is the sum over the top terms in a topic model:<br />
<span class="math display">\[ \sum_{w_i, w_j \in W_t} \text{Score}(w_i, w_j), \]</span> with top terms <span class="math inline">\(W_t\)</span> for each topic <span class="math inline">\(t\)</span>.</p>
<p>The coherence score used in the <code>SpeedReader</code> coherence function just uses the internal coherence of the top terms. I compared the scores for the top 3, 5 and 10 terms.</p>
<pre class="r"><code>coh_tbl &lt;- readRDS(here::here(&quot;inst&quot;, &quot;data&quot;, &quot;coherence.RDS&quot;))
coh_tbl &lt;- coh_tbl %&gt;% mutate(nterms = forcats::fct_inorder(nterms))

# TODO: sort number of terms in order

coh_tbl %&gt;% ggplot(aes(x = ntopics, y = coherence, group = nterms)) + geom_point(aes(colour = nterms, 
    group = nterms), size = 2) + geom_line(aes(color = nterms)) + scale_color_manual(values = pal21(), 
    guide = guide_legend(title = &quot;Number of terms&quot;)) + scale_x_continuous(breaks = coh_tbl$ntopics) + 
    labs(x = &quot;Number of topics&quot;, y = &quot;Coherence&quot;, title = &quot;Term coherence of LDA models&quot;, 
        subtitle = &quot;Coherence scores (higher is better) for top 3, 5 and 10 terms&quot;) + 
    theme_scatter(bgcol = &quot;#f8f8f8&quot;)</code></pre>
<p><img src="figure/train-model.Rmd/coherence-score-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="cluster-scoring" class="section level2">
<h2>Cluster scoring</h2>
<p>We can also treat the LDA models as clustering the Lego sets. We can assign the Lego set to the color topic which has the highest value for that document; This is the topic that is most responsible for generating the document.</p>
<p>The previous plot should indicate whether documents are getting strongly associated with a topic or if topics are to evenly distributed over all documents.</p>
<div id="clustering-sets-with-kmeans" class="section level3">
<h3>Clustering sets with kmeans</h3>
<p>In this next section, I cluster documents using both kmeans and LDA topics. Kmeans is intended as a simple baseline clustering method and sets are clustered based on their term vectors weighted by TF-IDF scores.</p>
</div>
<div id="cluster-analysis" class="section level3">
<h3>Cluster analysis</h3>
<p>The clusters scores include Rand, adjusted Rand, Folkes-Mallow and Jaccard scores. All try to score a clustering on how well the discovered labels match the assigned labels – here the <code>root_id</code> of the set. The Rand index assigns a score based on the number pairwise agreement of the cluster labels with the original labels. The other measures are somewhat similar in approach.</p>
<p>The scores behave similarly for both clustering methods but I’m not sure the results are helpful for determining the best <span class="math inline">\(k\)</span>. These labels might not match actual color themes and some theme ids may correspond well to a color topic while other themes may have no coherent color scheme.</p>
</div>
</div>
<div id="topic-distribution" class="section level2">
<h2>Topic Distribution</h2>
<p>Another way to evaluate the quality of the topic models is to see how well do. This example follows a <a href="http://tidytextmining.com/nasa.html#calculating-tf-idf-for-the-description-fields">this section</a> from the tidy text mining book.</p>
<p>The topic model’s ‘gamma’ matrix has the distribution of topics over models. The plot below visualizes this as how the <em>topics</em> are distributed over the probability bins for each topic. If too many topics have sets or documents in the low probability bins then you may have too high a number of topics since few documents are being strongly associated with any topic.</p>
<p>For our lego sets at 10 topics, the number of documents in high probability bins is already getting sparse while at 5 the documents are better distributed over each topic. For most topics, only the first 2-5 terms were closely related to the topic so it is not surprising that the 10 term coherence drops off quickly. In any case, the coherence measure doesn’t tell us much. If we assume that only 3 terms are significant the plot does show there is not too much decline in coherence up to <span class="math inline">\(k = 10\)</span>.</p>
<p>Following the tidytext book, look at the distribution over topics.</p>
<p><img src="figure/train-model.Rmd/plot-40-topics-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
